[《设计数据密集型应用》读书笔记（前九章）](https://zhuanlan.zhihu.com/p/43608920)

[数据密集型应用系统设计（DDIA）读书笔记（1～5章）](https://blog.csdn.net/breavo_raw/article/details/105274856)

[数据密集型应用系统设计（DDIA）读书笔记（6～9章）](https://blog.csdn.net/breavo_raw/article/details/105431780)

[数据密集型应用系统设计（DDIA）读书笔记（10～12章)](https://www.codenong.com/cs106393507)




## 第一章  可靠、可扩展、可维护的应用系统

构成数据密集型系统的基本模块 P11

硬盘的平均无故障时间（MTTF）约为10～50年 P15

滚动升级 P16

假定“人”是不可靠的，那么该如何保证系统的可靠性呢？ P17

即使一个系统现在工作可靠，并不意味着他将来一定能够可靠运转。
* 发生退化的一个常见的原因是负载增加
* 如果系统以某种方式增长，我们应对增长的的措施有哪些。
* 我们该如何添加计算资源来处理额外的负载

描述负载（Twitter的负载） P18

描述性能 P20

响应时间异常的可能原因 P21

如果想知道典型的响应时间，平均值并不是合适的指标，因为他掩盖了一些信息，无法告诉有多少用户实际经历了多少延迟
* 因此最好使用百分位数 P21
* 中位数称为50百分位数（缩写p50，另外还有p95，p99，p999）
针对负载增加的情况，可采用自动弹性系统和手动 P24

可维护性 P25

一个优秀的运营团队至少负责以下内容 P25

简单性是我们构建系统的关键目标之一
* 简化系统并不意味着减少系统功能，而主要意味着消除意外方面的复杂性 P27
* 消除意外复杂性的最好手段之一是抽象，一个好的设计抽象可以赢隐藏大量的实现细节

可演化性：易于改变


## 二、数据模型与查询语言

主要有关系模型，文档模型和一些基于图的模型

采用noSQL的几个驱动因素 P35

比尔盖茨的简历 P37
* 如果在关系模式中读取一份简历，那么需要执行多路查询，要么需要执行混乱的多路链接
* 而对于JSON的表示方法，所有相关信息都在一个地方，一次查询就够了
* 用户简历到用户的职位，教育历史和联系信息的一对多关系，意味着数据存在树状结构，JSON表示将数结构显式化

当使用ID时，对人类有意义的信息都存储在一个地方，引用它的所有内容都使用ID（ID只在数据库中有意义）；当直接存储文本时，则使用它的每条记录中都保存了一份这样的可读信息。 P38

如果复制了多份重复的数据，那么该模式通常就违背了规范化 P39

文档数据库的比较 P43

当集合中的数据不具有相同的结构时，（关系）模式带来的困扰大于他所能提供的帮助，无模式文档可能是更自然的数据模型。但是，当所有记录都有相同的结构时，模式则是记录和确保这种结构的有效机制。 P45

存储局部性的性能优势 P45
* 局部性优势仅适用需要同时访问文档大部分内容的场景

融合关系模型与文档模型是未来数据库发展的一条很好的途径 P46

声明式语言通常合适于并行执行，而命令式代码由于制定了特定的执行顺序，很难在多核和多台机器上并行化 P47

MapReduce查询 P50
* MapReduce是一种编程模型，用于在许多机器上批量处理海量数据，兴起于Google
* MongoDB支持有限的MapReduce方式在大量的文档上执行只读查询

图状数据模型 P52

对于声明式查询语言，通常在编写查询语句时，不需要指定执行细节：查询优化器会自动选择效率最高的执行策略，因此开发者可以专注于应用的其他部分。

Datalog 基础 P62

小结 P65


## 三、数据存储与检索

主要讨论日志结构的存储引擎和面向页的存储引擎 P71

一个世界上最简单的数据库 P72

许多数据库内部使用日志（log），日志是一个仅支持追加式更新的数据文件 P72

索引是基于原始数据派生而来的数据结构。很多数据库允许单独添加和删除索引，而不影响数据库的内容，他只会影响查询性能

* 维护额外的结构势必会引入开销，特别是在新数据写入时 P73

哈希索引 P73

哈希表索引的局限性 P76

SSTable（排序字符串列表）：key-value对的顺序按键排序，要求每个键在每个合并的段文件中只能出现一次

Lucene是Elasticsearch和solr等全文搜索系统所使用的索引引擎，它采用了类似SSTable的方法来保存其字典。

* 全文索引比key-value复杂得多，但它基于类似的想法：给定搜索查询中的某个单词，找到提及该单词的所有文档（网页，产品描述等）。
* 它主要采用key-value结构实现，其中键是单词（词条），值是包含该单词的文档ID的列表（倒排表）。在Lucene中，从词条到posting list的映射关系保存在类SSTable的排序文件中，这些文件可以根据需要在后台合并。

SSTable相关的性能优化 P80

最广泛使用的一种数据结构：B-tree P80
* 像SSTable一样，B-tree保留按键排序的key-value对，这样可以实现高效的key-value查询和区间查询。但相似仅此而已：B-tree本质上具有非常不同的设计理念 P81

日志结构索引将数据分解为可变大小的段，B-tree将数据分解成固定大小的页（一般为大小4kb左右）

* 页是内部读/写的最小单元
* 这种设计更接近底层硬件，因为磁盘也是以固定大小的块排列

具有n个键的B-tree总是具有O（log n）的深度。 P82

* 大多数数据库可以适合3～4层的B-tree，因此不需要遍历非常深的页面层次即可找到所需的页（分支因子为500的4KB页的四级树可以存储高达256TB）

预写日志（write-ahead log WAL），也称为重做日志（仅支持追加修改），用于在数据库崩溃时，将B-tree恢复到最近一致的状态

B-tree的优化 P83

B-tree和LSM-tree P84

其他索引结构 P86

聚集索引（在索引中直接保存行数据）

非聚集索引（仅储存引用中的数据的引用）

覆盖索引（折中方案）

多列索引 P86
* 级联索引
* 多维索引
* 空间索引

全文搜索和模糊索引 P88

在内存中保存所有内容 P88

与直觉相反，内存数据库的性能优势并不是因为他们不需要从磁盘读取。如果有足够的内存，即使是基于磁盘的存储引擎，也可能永远不需要从磁盘读取，因为操作系统将最近使用的磁盘块缓存在内存当中。
* 相反，内存数据库可以更快，是因为他们避免了使用写磁盘的格式对内存数据接口编码的开销

反缓存方法（内存数据架构扩展到远大于可用内存的数据集，方法类似于操作系统对虚拟内存和交换文件的操作，但能更加有效的管理内存） P89

事务，主要指组成一个逻辑单元的一组读写操作 P89

对比事务处理（OLTP）与分析系统（OLAP）的主要特性 P90

数据仓库 P91

* 是单独的数据库，分析人员可以在不影响OLTP操作的情况下尽情的使用
* 数据仓库包含公司所有各种OLTP系统的只读副本

将数据导入仓库的过程称为提取-转换-加载（Extract-Transform-Load, ETL）P91

使用单独的数据仓库而不是直接查询OLTP系统进行分析，很大的优势在于数据仓库可以针对分析访问模式进行优化，事实证明，之前讨论的索引算法适合OLTP，但不擅长应对分析查询。

数仓模型：星型模式和雪花模型

在典型的数据仓库中，表通常非常宽：事实表通常超过100列，有时候有几百列，纬度表也可能非常宽，可能包括与分析相关的所有元数据。P94

根据列中的具体模式，可以采用不同的压缩技术。在数据仓库中特别有效的一种技术是位图编码。 P96

面向列存储（列压缩） P99

物化视图：一个类似表的对象，其内容是一些查询的结果，常用于OLAP当中…



## 四、数据编码与演化

滚动升级（分阶段发布），每次将新版本部署到少数几个节点，检查新版本是否正常运行，然后逐步在所有节点上升级新代码，这样新版本部署无需服务暂停，从而支持更频繁的版本发布和更好的演化。 P109

向前兼容，向后兼容 P110

程序通常使用（至少）两种不同的数据表示形式 P110

* 在内存中，数据保存在对象，结构体，列表，数组，哈希表和树等结构中。这些数据结构针对CPU的高效访问和操作进行了优化（通常使用指针）
* 将数据写入文件或通过网络发送时，必须将其编码为某种字包含的字节序列（例如Json文档）。由于指针对其他进程没有意义，所以这个字节序列表示看起来与内存中使用的数据结构大不一样。

从内存中的表示到字节序列的转化称为编码（或序列化），相反的过程称为解码（或解析，反序列化）

不同语言编码库带来的一些深层次问题 P111

不同的标准化编码（Json，XML，CSV） P111

对于仅在组织内部使用的数据，可以选择更紧凑或更快的解析格式。对于一个小数据集来说，收益可以忽略不计，但一旦达到TB级别，数据格式的选择就会产生很大的影响。 P113

AVRO的读模式与写模式 P118

Protocol Buffers、Thrift和Avro都使用了模式来描述二进制编码格式。它们的模式语言比XML模式或JSON模式简单的多 P123

Json、XML、CSV与基于模式的二进制编码的对比（二进制的一些不错的属性） P124
* 它们可以比各种“二进制Json”变体更紧凑，可以省略编码数据中的字段名称。
* 模式是一种有价值的文档形式，因为模式时解码所必须的，所以可以确定它是最新的（而手动维护的文档可能很容易偏离现实）
* 模式数据库允许在部署任何内容之前检查模式更改的向前和向后兼容性
* 对于静态类型编程的用户来说，从模式生成代码的能力是有用的，它能够在编译时进行类型检查

数据流模式，最常见的进程间数据流动的方式： P124
* 通过数据库
* 通过服务调用
* 通过异步消息传递

数据比代码更加长久 P126

微服务 P127
* 服务本身可以是另一项服务的客户端（例如，典型的web应用服务器作为数据库的客户端）。
* 这种方法通常用于将大型应用程序按照功能区分分解为较小的服务，这样当一个服务需要另一个服务的某些功能或数据时，就会向另一个服务发出请求。这种构建应用程序的方式传统上被称为面向服务的体系结构（SOA），最近则更名为微服务体系结构
* 两种流行的web服务方法：REST和SOAP P128

swagger P129

远程过程调用（RPC）的一些缺陷 P129
* 本地函数调用时可预测的…
* 网络请求有另一种结果：超时
* 重试失败请求，可能会发生请求实际上已经完成，只是响应丢失的情况。
* 调用本地函数，通常需要大致相同的时间来执行，而网络请求则无法预测。
* 调用本地函数时，可以高效的将引用（指针），传递给本地内存对象中。进行网络请求时，参数都需要进行编码。对于较大的对象来说，很容易出现问题。
* 客户端和服务可以用不同的编程语言来实现，所以RPC框架必须将数据类型从一种语言转换成另一种语言。

尝试使用远程服务看起来像编程语言中的本地对象一样毫无意义 P130

RESTful Api的一些显著优点： P131
* 它有利于实验和调试
* 支持所有的主流编程语言和平台
* 并且有一个庞大的工具生态系统

异步消息队列
* 异步消息队列的优点： P132
	* 如果接收方不可用或过载，他可以充当缓冲区，从而提高系统的可靠性
	* 他可以自动将消息重新发送到崩溃的进程，从而防止消息丢失
	* 它避免了发送方需要知道接收方的IP地址和端口号（这在虚拟机经常容易起起停停的云部署中特别有用）
	* 它支持将一条消息发送给多个接收方
	* 它在逻辑上将发送方与接收方分离（发送方只是发布消息，并不关心谁使用它们）
* 然而消息传递通信通常是单向的
* 但是我们可以在实现一个回复队列，该队列由原始消息发送者来消费（即可以实现类似RPC的请求/响应数据流）

消息代理
* RabbitMQ
* Apache Kafka

三种流行的分布式Actor框架处理消息编码的方式如下 P133



## 第五章  分布式数据系统

在多台机器上分布数据的理由
* 扩展性
* 容错与高可用性
* 延迟考虑

系统扩展的几种架构 P140
* 共享内存架构（硬件成本高）
* 共享磁盘架构（频繁的资源竞争）
* 无共享架构（节点独立）✔

将数据分布在多节点时有两种常见的方式 P141
* 复制
	* 在多个节点上保存相同数据的副本
	* 数据复制方案的难点在于处理那些需要持续更改的数据 P145
	* 三种流行的复制数据变化的方法
		* 主从复制
		* 多主节点复制
		* 无主节点复制
* 分区
	* 将一个大块头的数据拆分成多个较小的子集即分区，不同的分区分配给不同的节点（也称为分片）
	
* 上述两者经常结合使用

每个保存数据库完整数据集的节点称之为副本 P146

主从复制的基本原理 P146

同步复制与异步复制 P147

把所有节点都配置为同步复制有些不切实际。 P148

在实践中，如果数据库启用了同步复制，通常意味着其中某一个从节点是同步的，而其他节点是异步模式。 P148

	* 万一同步的从节点变得不可用或者性能下降，则将另一个异步的从节点提升为同步模式。

	* 这样可以保证至少有两个节点拥有最新的数据副本。

	* 这种配置称为半同步

主从复制还经常会被配置为全异步模式，不管从节点上数据多么滞后，主节点总是可以继续相应写请求，系统的吞吐性能更好。

如何配置新的从节点 P149

处理节点的失效 P149
* 从节点失效：追赶式恢复
* 主节点失效：节点切换
* 切换节点的风险 P151

上述问题，包括节点失效、网络不可靠、副本一致性、持久性、可用性和延迟之间的各种细微权衡，实际上正是分布式系统核心的基本问题。 P151

基于预写日志（WAL）传输 P152

基于行的逻辑日志复制 P153

基于触发器的复制 P154
* 借助许多关系数据库都支持的功能：触发器和存储过程

最终一致性 P155

复制滞后问题
	* 读自己的写
	* 读写一致性 P156
		* 可行方案
	* 单调读 P157
		* 单调读保证，如果某个用户一次进行多次读取，则他绝对不会看到回滚现象，即在读取较新值之后又发生读旧值的情况 P157
	* 前缀一致读（分区数据库中出现的一种特殊问题）
		* 该保证是说，对于一系列按照某个顺序发生的写请求，那么读取这些内容时也会按照当时写入的顺序。

复制滞后的解决方案 P159
	* 多主节点复制
		* 适用场景 P162
			* 多数据中心
			* 离线客户端操作
			* 协作编辑
	* 需要解决冲突问题
	* 处理冲突最理想的策略是避免冲突 P164
	* 系统必须收敛于一致状态
	* 自定义冲突解决逻辑
		* 解决冲突最合适的方式可能还是依靠应用层，所以大多数节点复制模型都有工具来让用户编写应用代码来解决冲突 P165
		* 在写入时执行
		* 在读取时执行
	* 自动冲突解决 P166
		* 操作转换，在线协作编辑应用背后的冲突解决算法 P166

复制的拓补接口 P166
* 环形拓补
* 星型拓补
* 全部-至-全部拓补

quorum读写 P170

无主节点复制由于旨在更好的容忍写入冲突，网络中断和延迟尖峰等，因此也可适用于多数据中心操作

处理写冲突
* 最终写入者获胜 P176

并发性，时间和相对性 P178
	* 如果两个操作并不需要意识到对方，我们即可以声称他们是并发操作

确定前后关系，一种确定并发操作性的算法 P178

合并同时写入的值 P180

版本矢量


在本书中都有多次提及并进行了详细的讨论（例如：数据分区，事务，ACID，分布式系统，CAP理论, 两阶段提交, ZooKeeper等）



## 第6章  数据分区

面对一些海量数据或非常高的查询压力，复制技术还不够，我们还需要将数据拆分成为分区，也称为分片 P189

分区的定义：每一条数据只属于某个特定分区，每个分区都可以视为一个完整的小型数据库，虽然数据库可能存在一些跨分区的成分 P189

采用数据分区的主要目的是提高可扩展性，不同的分区可以放在一个无共享集群的不同节点上 P189

分区与复制通常结合使用 P190

分区的主要目的是将数据和查询负载均匀分布在所有节点上

分区不均匀会导致“倾斜” P191

基于关键字的分区 P191

基于关键字哈希值分区 P193

* 一致性哈希

二级索引技术是Solr和Elasticsearch等全文索引服务器存在之根本 P195

* 基于文档分区的二级索引

* 基于词条的二级索引分区

分区在平衡 P198

* 随着时间的推移，分区数据总会出现一些变化，这些变化要求数据和请求可以从一个节点转移到另一个节点

* 这样一个迁移负载的过程称为再平衡（or 动态平衡）

* 无论哪种分区方案，分区再平衡通常至少满足

	* 平衡之后，负载、数据存储、读写请求等应该再集群范围更均匀的分布

	* 在平衡执行过程中，数据库应该可以继续正常提供读写服务

	* 避免不必要的负载迁移，以加快动态平衡，并减少网络和磁盘I/O影响

动态再平衡策略 P198

* 取模的缺点

* 使用固定数据量的分区 p199

* 动态分区

	* 当分区的数据增长超过一个可配的参数阈值（HBase上默认是10GB），他就拆分为两个分区，每个承担一半的数据量，相反，如果有大量的数据被删除，并且分区缩小到某个阈值以下，则将其与相邻分区进行合并。该过程类似于B树的分裂操作

	* 预分裂

* 按节点比例分区

请求路由

* 现在已经将数据集分布到多个节点上，但是仍有一个悬而未决的问题，当客户端需要发送请求时，如何知道应该连接哪个节点？如果发生了分区再平衡，分区与节点的对应关系随之还会变化。

几种不同的路由处理策略 P202

* 允许客户端链接任意的节点，如果恰好拥有所请求的分区，则直接处理该请求，否则，将请求转发到下一个合适的节点

* 将所有请求发送到一个路由层，由其进行转发

* 客户端感知分区和节点的关系。此时，客户端可以直接连接到目标节点，而不需要任何中介。

 

## 第7章   事务

事务将应用程序的多个读、写操作捆绑在一起成为一个逻辑操作单元。即事务中的所有读写是一个执行的整体，整个事务要么成功（提交）、要么失败（终止或回滚）。如果失败，应用程序可以安全的重试

ACID的含义：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）与持久性（Durability）

不符合ACID标准的系统被冠以BASE，即基本可用性（Basically Available）、软状态（soft state）和最终一致性（Eventual consistency），但这基本没有什么实际作用

原子性定义的特征是：再出错时终止事务，并将部分完成的写入全部丢弃。

一致性 P214

* 一致性非常重要，但它在不同场合有着不同的具体含义，例如：

	* 讨论副本一致性以及异步复制模型时，引出了最终一致性问题（参阅第五章复制滞后问题）

	* 一致性哈希则是某些系统用于动态分区再平衡的方法（参见第6章一致性哈希）

	* CAP理论中，一致性一次用来表示线性化（参见第9章“可线性化”）

	* 而在ACID中，一致性主要指数据库处于应用程序所期待的“预期状态”

* ACID中的一致性主要是指对数据有特定的预期状态，任何数据更改必须满足这些状态约束（或者恒等条件）

原子性，隔离性和持久性是数据库自身的属性，而ACID中的一致性更多的是应用层的属性

隔离性 P215

* 并发执行的多个事务相互隔离，他们不能互相交叉

持久性 P215

* 持久性保证一旦事务提交成功，及时存在硬件故障或数据库崩溃，事务所写入的任何数据也不会消失

对于某个特定链接，SQL语句BEGIN TRANSACTION和COMMIT之间的所有操作和属于同一个事务

单对象写入 P219

通常意义上的事务针对的是多个对象，将多个操作聚合为一个逻辑执行单元 P219

**弱隔离级别 P221**

* 读提交是最基本的事务隔离级别，它只提供以下两个保证

	* 读数据库时，只能看到已成功提交的数据（防止脏读）

	* 写数据库时，只会赴会已经成功提交的数据（防止脏写）

* 数据库通常采用行级锁来防止脏写 p224

	* 当事务想修改某个对象（例如行或文档）时，它必须首先获得该对象的锁；然后一直持有锁直到事务提交（或终止）后，才能获得锁并继续 P224

* 防止脏写（采用读锁并不可行，运行较长时间的写事务会导致许多只读的事务等待太长时间）

	* 对于每个待更新的对象，数据库都会维护其旧值和当前持锁事务将要设置的新值两个版本。在事务提交之前，所有其他读都读取旧值；仅当写事务提交之后，才会切换到读取新值

**快照级别隔离与可重复读 P225**

* 如果查询的是数据库在某时刻点所冻结的一致性快照，则查询结果的含义非常明确

* 多版本并发控制（MVCC） P227

	* 考虑到多个正在进行的事务可能会在不同的时间点查看数据库状态，所以数据库保留了对象多个不同的提交版本，这种技术因此也被称为多版本并发控制

	* 典型的做法是，在读-提交级别下，对每一个不同的查询单独创建快照；而快照级别隔离则是使用一个快照来运行整个事务。

一致快照的可见性原则 P228

处理两个写事务并发的解决方案 P230

* 原子写操作，如果原子操作可行，那么它就是推荐的最佳方式

* 显式加锁

* 自动检测更新丢失 P232

* 原子比较和设置

* 冲突解决与复制

* 写倾斜与幻读 P233

写倾斜与幻读 P233

* 可以讲写倾斜视为一种更为广义的更新丢失问题。即如果两个事务读取相同的一组对象，然后更新其中一部分。

* 不同事务可能更新不同的对象，则可能发生写倾斜；

* 而不同的事务如果更新的是同一个对象，则可能发生脏写或更新丢失。

* 解决方案

	* 串行化隔离级别

	* 对事务依赖的行进行显式的加锁 P235

* 更多写倾斜的例子（会议室预定系统，多人游戏，声明一个用户名，防止双重开支） P236

* 产生写倾斜的原因 P236

幻读 P237

* 在一个事务中的写入改变了另一个事务查询结果的现象，称为幻读

实体化冲突解决幻读（书中不建议这么做）

串行化 P237

* 解决并发的方式是避免并发

* 串行执行小结，当满足以下约束条件时，串行执行事务可以实现串行化隔离

	* 事务必须剪短而高效，否则一个缓慢的事务会影响到所有其他事务的执行性能；

	* 仅限于活动数据集完全可以加载到内存的场景。有些很少访问的数据可能会被移到磁盘，但万一单线程事务需要访问它，就会严重拖累性能

	* 写入吞吐量必须足够低，才能在单个CPU核上处理；否则就需要采用分区，最好没有跨分区事务

	* 跨分区事务虽然也可以支持，但是占比必须很小

两阶段加锁 P242

快照级别隔离的口号“读写互不干扰” P243

谓词锁 P244

* 作用类似于之前描述的共享/独占锁，而区别在于，他并不属于某个特定的对象，而是作用与满足某些搜索条件的所有查询对象。

索引区间锁 P245

可串行化快照隔离 P246
 

## 第8章  分布式系统的挑战

在分布式系统中，可能会出现系统的一部分工作正常，但其他某些部分出现难以预测的故障，称之为“部分失效”

无共享并不是构建集群系统的唯一方式，但它却是构建互联网服务的主流方式 P263

不可靠的网络 P262

检测故障 p265

* 许多系统都需要自动检测节点失效这样的功能，例如：

	* 负载均衡器要避免向已失效的节点继续分发请求（即将其做下线处理）

	* 对于主从复制的分布式数据库，如果主节点失败，需要将某个从节点提升为主节点。不过，由于网络的不确定性很难准确判断节点是否确实失效。


超时是故障检测的有效办法，但不幸的是，超时的时常没有标准可言 P266

网络拥塞与排队

* 驾车时往往由于交通堵塞，导致行车时间变化很大，同样，计算机网络上数据包延时的变化根源往往在于排队 P267

为什么数据中心网络和互联网采用分组交换而不是电路交换网络呢？答案是，他们针对突发流量进行了很多优化 P270

总之，当前广泛部署的技术无法为我们提供延迟或可靠性方面的硬件级保证，我们必须假设会出现网络拥塞，排队，和无上限的延迟。基于此，超时设置并不存在绝对正确的值，而是需要通过实验的方式来确定。 P270

延迟与资源利用率 P271

* 如果资源总是静态分配（例如，专用硬件和预留带宽分配），则某些环境下可以保证延迟的确定性。但是，这是以降低资源使用率为代价的，换句话说，其成本过于昂贵，而多租户、动态资源分配方式则可以提供更高的资源使用率，因而成本更低，当然也引入了可变延迟的缺点

* 网络中的可变延迟并不是一种自然规律，只是成本与收益互相博弈的结果

分布式系统多节点间复制数据时，可能由于时钟的时间差导致数据库写入丢失 P276

快照隔离，广泛用于小数据量，快速读写的事务以及大数据量，长时间运行的只读事务（例如设备分析），可以在数据库的某个一致状态上不需加锁、不违背读写隔离性的前提下高效支持只读事务。 P 278

开发实时系统代价昂贵的原因 P282

知识，真相与谎言 P282

如果节点存在“撒谎”的情况（即故意发送错误的活破坏性的响应），那么分布式系统处理的难度就上了一个台阶。例如，节点明明没有收到某条消息，但却对外声称收到了。这种行为称为拜占庭故障，在这样不信任的环境中需要达成共识的问题也被称为拜占庭将军问题 P286

在绝大多数服务器端数据系统中，部署拜占庭容错解决方案基本不太可行。

* 系统协议异常复杂

* 依赖于硬件层面的支持

对于真实系统的建模，最普遍的组合是崩溃-恢复模型结合部分同步模型。 P290


## 第9章  一致性与共识

分布式系统可能发生的故障：数据包丢失、顺序紊乱、重复发送或者延迟、时钟偏差、节点暂停（例如由于垃圾回收）甚至随时崩溃

分布式系统最重要的抽象之一就是共识：所有的节点就某一项提议达成一致 P303

为了使系统可线性化，需要添加一个重要的约束：一旦某个读操作返回了新值，之后所有的读（包括相同或不同客户端）都必须返回新值 P308

可线性化与可串行化的区别 P311

主从复制的系统需要确保有且只有一个主节点，否则会产生脑裂；选举行的主节点的常见的方法是使用锁：即每个启动的节点都试图获得锁，其中只有一个可以成功，即称为主节点。 P311

不管锁具体如何实现，他必须满足线性化：所有节点都必须同意哪个节点持有锁，否则就会出现问题。

线性化本质上意味着“表现的好像只有一个数据副本，且其上的所有操作都是原子的 ”。 P313

**CAP理论 P317**

不要求线性化的应用更能容忍网络故障，这种思路通常被称为CAP定理

CAP有时也代表一致性，可用性，分区容错性，系统通常只能支持其中两种特性。 P317

* 不过，上述理解存在误导性，网络区分是一种故障，不管喜欢还是不喜欢，它都可能发生，所以无法选择或逃避区分的问题。

* 在网络正常的时候，系统可以同时保证一致性（线性化）和可用性，而一旦发生了网络故障，必须要么选择线性（一致性），要么可用性。因此，更准确的称呼应该是“网络区分情况下，选择一致还是可用”。

* 围绕了CAP有太多的误解与困扰，最后反而无法帮助我们更好的理解系统（书中建议所以最好避免使用CAP）

之所以放弃线性化的原因就是性能，而不是为了容错。 P318

在可线性化数据存储中不存在并发操作，一定有一个时间线将所有操作都全序执行。 P321

可线性化一定因为着因果关系 P322

Lamport时间戳 P325

* Lamport时间戳与物理墙上时钟并不存在直接对应关系，但它可以保证全序：给定两个Lamport时间戳，计数器较大的那个时间戳大；如计数器值正好相同，则节点越大，时间戳越大。

全序关系广播 P327

全序关系广播正式数据复制所需要的：如果每条消息代表数据库写请求，并且每个副本都按相同的顺序处理这些请求，那么所有副本可以保持一致（或许有些滞后）；该原则也被称为状态机复制。 P328

分布式事务与共识 P330

* 共识问题是分布式计算中最重要也是最基本的问题之一。表面上看，目标只是让几个节点就某件事达成一致。这似乎很简单，或者至少不应该太难。不幸的是，许多失败的系统正式由于低估了这个问题所导致的。

需要集群节点达成一致的部分重要场景 P331

* 主节点选举

* 原子事务提交

两阶段提交（2PC）算法是解决原子提交最常见的方法。在各种数据库、消息系统和应用服务器中都有实现。

单节点上，事务的提交非常依赖于数据持久写入磁盘的顺序关系：先写入数据，然后在提交记录。 P322

事务提交（或）终止的关键点在于磁盘完成日志记录的时刻：在完成日志记录写之前如果发生了崩溃，则事务需要终止;

如果在日志写入完成之后，即使放生崩溃，事务也被安全提交。

通常2PC事务从应用程序在多数据库节点上执行数据读/写开始。我们将这些数据库节点称为事务中的参与者。当应用程序准备提交事务时，协调者开始阶段1:发送一个准备请求到所有节点，询问他们是否可以提交。协调周然后跟踪参与者的回应 P334

* 如果所有参与者回答“是”，表示他们已经准备好提交，那么协调者接下来在阶段2会发出提交请求，提交开始实际执行

* 如果有任何参数者会回复“否”，则协调者在阶段2中想所有节点发送放弃请求

2PC协议有两个关键点 P336

* 当参与者投票“是”时，它做出肯定提交的承诺（尽管还取决于其他参与者的投票，协调者才能做出做后的决定）

* 协调者做出了提交（或者放弃）的决定，这个决定也是不可撤销。正是这两个承诺确保了2PC的原子性

* 单节点的原子提交其实是将两个事件合二为一，写入事务日志即提交。

协调者发生故障 P336

* 如果在决定到达之前，出现协调者崩溃或者网络故障，则参与者只能无奈等待。此时参与者处在一种不确定的状态。

* 2PC能够顺利完成的唯一方法是等待协调者恢复。

两种不同的分布式数据库概念 P338

* 数据库内部的分布式事务

* 异构分布式事务

XA事务 P339

XA事务解决了多个参与者之间如何达成一致这样一个非常现实而重要的问题，但也引入了不少操作方面的限制 P341

共识问题总结 P341

* 通过使用共识算法来决定这些不相容的操作之中谁是获胜者

共识算法必须满足以下性质 P342

* 协商一致性，所有节点都接受相同的协议

* 诚实性，所有节点不能反悔，即对一项提议不能有两次决定

* 合法性，如果决定了值v，则v一定是由某个节点所提议的

* 可终止性，节点如果不崩溃最终一定可以达成决议

全序关系广播相当于持续的多轮共识（每一轮共识决定对应于一条消息） P343

Epoch：世代编号，对于主从复制

* 如果法相当前的主节点失效，节点就开始一轮投票选举新的主节点。

* 选举会赋予一个单调递增的epoch号

* 如果出现了两个不同的节点对应于不同epoch号码（例如上一个epoch号码的主节点其实并没有正真挂掉），则具有更高epoch号码的主节点将获胜

共识的局限性 P345

ZooKeeper和etcd主要针对保存少量、可完全载入内存的数据（虽然他们最终仍要写入磁盘以支持持久性）而设计，所以不要用他们保存大量的数据。他们通常采用容错的全序广播算法在所有节点上复制这些数据从而实现高可靠 P347



## 第10章 派生数据

整合不同系统是大型应用中最为关键的任务之一 P363

记录系统 P363

* 一个记录系统被称为真实数据系统，拥有数据的权威版本。

* 如果另一个系统与记录系统之间存在任何差异，那么以记录系统中的数据值（按照定义）为准

派生数据系统 P364

* 派生数据系统中的数据则是从另一个系统中获取已有数据并以某种方式进行转换或处理的结果

* 如果派生数据丢失，用户可以从原始数据源进行重建。

* 一个典型的例子是缓存

在线服务/系统 P367

* 服务等待库户请求或指令的到达，收到请求或指令时，服务试图尽快地处理它，并返回一个相应

* 响应时间和可用性是服务性能的主要衡量指标

批处理系统 P367

* 批处理系统接受大量的输入数据，运行一个作业来处理数据，并产生输出数据。

* 批处理作业的衡量标准通常是吞吐量

流处理系统 P368

* 介于在线与离线/批处理之间（有时称为近实时或近线处理）

著名的批处理算法MapReduce P368

* MapReduce值得深入理解，因为他清晰的解释了批处理为什么有用以及如何有用

nginx默认访问日志格式 P369

简单的日志分析 P369

* 利用nginx日志找出网站中前五个最受欢迎的网页

令人惊讶的是，使用awk、sed、grep、sort、uniq、和xargs的组合，可以在几分钟内完成许多数据分析任务，并且表现令人十分满意 P370

归并排序在磁盘上有良好的顺序访问模式 P371

通过管道将程序连接起来的想法成为如今的UNIX哲学，在开发人员和UNIX用户中逐渐变得流行的一些列设计原则 P372

**UNIX哲学 P372**

* 每个程序做好一件事。如果要做新的工作，则建立一个全新的程序，而不是通过增加新“特征”使旧程序变得更加复杂。

* 期待每个程序的数据成为另个尚未确定的程序的输入。不要将输出与无关信息混淆在一起。避免使用严格的表格状或二进制输入格式。不要使用交互式输入

* 尽早尝试设计和构建软件，甚至是操作系统，最在几周内完成。需要扔掉那些笨拙的部分时不要犹豫，并立即进行重建

* 优先使用工具来减轻编程任务，即使你不得不额外花费时间去构建工具，并缺预期在使用完成后会将其中一些工具扔掉

MapReduce与分布式文件系统 P375

MapReduce有点像分布在数千台机器上UNIX工具。MapReduce作业可以和UNIX进程相媲美：需要一个或多个输入，并产生一个或多个输出。P375

MapReduce作业执行流程 P376

要创建MapReduce作业，需要实现两个回调函数，即mapper和reducer P377

当mapper完成肚脐输入文件并写入经过排序的输出文件，MapReduce调度器就会通知reducer开始从mapper中获取输出文件。 P378

MapReduce工作流 P379

Mapreduce没有索引概念，至少不是通常意义上的索引。 P380

当给定一组文件作为MapReduce输入时，他读取所有文件的全部内容；数据库将其称为全表扫描。 P380

* 读取少量记录代价昂贵

* 分析查询场景下较为合理

各种join P384～P386

对比Hadoop和分布式数据库 P390

Haddop经常被用于实现ETL过程：来自事物处理系统的数据以某种原始形式转储到分布式文件系统中，然后编写MapReduce作业进行数据清理，将其转换为关系表单，并将其导入MPP数据仓库以进行分析。数据建模仍然会发生，打它位于一个单独步骤中，与数据收集是分离的。由于分布式文件系统支持任何格式编码的数据，所以这种解偶是可行的 P391

Hadoop生态系统包括可以随机访问的OLTP数据库，如HBse以及MPP模式的分析数据库，如Impala

HBase和Impala都不使用MapReduce，但都使用HDFS进行存储。尽管它们份温和处理数据的方法差异很大，但是可以共存并被集成到同一个系统中。 P392

与在线系统相比，批处理对故障的敏感度较低，因为如果遇到失败的任务，它们不会立即影响用户，而且总是可以重新运行

MapReduce被设计为容忍意外任务终止的原因：不是因为软件不可靠，而是因为任意种植进程的灵活性能够更好的利用集群资源

通过处理阶段明确的建模数据的系统被称为数据流引擎。 P395

像MapReduce一样，他们通过反复调用用户定义的函数在单个线程上一次处理一条记录。他们通过对数据进行分区来进行并行工作，将一个功能输出复制到网络上，成为另一个功能的输入。 P395

回到UNIX类比，我们看到MapReduce就像是将每个命令的输出写入临时文件，而数据流引擎看起来更像是UNIX管道。尤其Flink是围绕流水线执行的思想建立起来的，也就是将运算符的数据递增地传递给其他运算符，并且在开始处理之前不等待输入完成。 P398

批量同步并行模型 P399

批处理引擎正被用于日益广泛的算法领域的分布式执行。随着批处理系统获得更丰富的内置功能和高级声明式运算符，而MPP数据库也变得更具可编程性和灵活性，两者开始变得更加相似：最终，他们都是用于存储和处理数据的系统。 P402



* 在UNIX世界中，允许多个程序组合在一起的统一接口是文件和管道；

* 在MapReduce中，该接口是分布式文件系统。我们看到数据流引擎添加了自己的管道式数据传输机制，以避免在分布式文件系统中将中间状态实体化，而作业的出书输入和最终输出通常仍然是HDFS

* 分布式批处理框架需要解决的两个主要问题是：

	* 分区

	* 容错


## 第11章  流处理系统

一个可用的复杂系统总是从可用的简单系统演进而来。反过来这句话也是正确的：从零开始设计的复杂系统从来都用不了，也没办法把它变成可用。 P413

批处理的问题：输入的更改只会在一天之后的输出中反映出来，这对于许多没有耐心的用户来说太慢了。

为了减少这种延迟，可以更频繁的运行处理，即在每秒钟结束时（甚至是不间断地）处理每秒的数据，完全放弃固定的时间片，每当有事件就开始处理。这就是流处理背后的思想。 P414

向消费者通知新事件的常见方法是使用消息系统：生产者发送包含事件的消息。 P415

消息代理 P416

不管保留多长时间的消息，因为每个消息都被写入到磁盘，因此日志的吞吐量基本保持不变。这种行为与将消息保存在内存中，仅当队列变得过大时才将他们写入磁盘的穿系统系统相比，差异明显：当队列很短的时候这些系统是很快的，当开始写入磁盘时，会变得很慢，因此吞吐量取决于保留的历史记录数量。 P423

没有一个系统能够满足所有的数据存储、查询和处理请求。在实践中，大多数重要的应用程序都需要结合多种不同的技术来满足需求： P424

* 使用OLTP数据库来为用户请求提供服务

* 使用缓存来加速常见请求

* 使用全文索引处理搜索查询

* 使用数据仓库用于分析

每个技术都有自己的数据副本，以自己的表示方法存储，并且针对自己的设计目标而优化

日志压缩：存储引擎定期查找具有相同key的日志记录，丢弃所有的重复项，并且只保留每个key的最新更新。 P428

事件溯源 P429

事件溯源的哲学史小心的区分事件和命令。 P430

事务日志记录了对数据库所做的所有更改。 P432

* 高速追加是更改日志的唯一方法，从这个角度来看，数据库的内容保存了日志中最新的记录值缓存。

* 日志是事实。数据库是是日志子集的缓存。

* 该缓存子集恰好是来自日志的每个记录和索引值的最新值

不变事件的优势 p432

如果发生错误，通常不会删除或更改错误的数据，而是增加新的数据弥补这些错误

覆盖错误的数据将导致数据恢复变得更加的困难。

通过不可变事件的追加日志，诊断问题和从问题中恢复就要容易的多

出于分析的目的，历史记录也能提供有用的消息

缓慢变化的维度 P446

批处理框架可以比较容易实现容错：如果MapReduce作业中的任务失败，可以简单地在另一台机器上重新启动，并丢弃失败任务的输出。这种透明的重试是可能的，因为输入文件是不可变的。每个人物都将其输出写到HDFS上的单独文件，并且输出仅在任务成功完成时可见 P446

流处理的容错 P446

总结:
* 在某些方面，流处理与批处理非常相似，但是它是对无限（永不停止）的流而不是固定大小输入进行持续处理 P449

* 将数据表示为流为高效集成系统提供了更多的机会 P450



## 第12章  数据系统的未来


派生视图允许逐步演变。如果想重新构建数据集，无需采用高风险的陡然切换。而是可以在同一个基础数据上的两个独立派生视图来同时维护新老两种架构。

* 然后，逐步开始将少量用户迁移到新视图中，以测试其性能是否有错误，而大多数用户将继续路由到旧视图。

* 之后，逐渐增加访问新视图的用户比例，最终放弃旧视图

* 这种逐渐迁移的美妙之处在于，如果出现问题，每个阶段的过程都是可以轻易反转：你总是有一个工作系统可以回退 P 468

分拆数据库 P469

* 从最抽象的层面上理解，数据库，Hadoop和操作系统都提供了相同的功能：他们保存某些数据，并支持处理和查询 。

* 许多文件系统不能好很地处理包含一千万个小文件的目录，而包含一千万条记录的数据库完全是正常的。

创建一个索引

* 想想在关系型数据库中运行CREATED INDEX来创建新索引会发生什么。

* 数据库必须扫描表的一致性快照，挑选出所有被索引的字段值，对他们进行排序，然后得到索引。

* 接下来，必须处理从一致性快照创建以来所累计的写入操作（假设表在创建索引时未被锁定，所以写操作可能会继续）。

* 完成后，只要有事物写入表中，数据库就必须保持索引处于最新状态。

构建你并不需要的扩展规模是在浪费精力，可能会把你限制在一个不灵活的设计当中。实际上，这是在做过早优化 P473

将stream operatoe组合成数据流系统与微服务理念有很多相似的特性。但是，底层的通信机制差异很大 P478

* 前者是单向、异步的消息流

* 后者是同步的请求/响应交互

首先创建派生数据集，很可能是因为想在以后多次查询它即读路径：当有用户访问请求时，从派生数据集中读取数据，做些必要处理，然后返回处理后的结果以响应用户。 P479

许多数据存储支持的读写操作其实都是一个请求对应一个响应，但很少支持订阅更改，即一段时间内会主动返回一系列的响应。 P482

为了将写路径扩展到最终用户，我们需要从根本上重新思考构建这些系统的方式：从请求/响应交互转向发布/订阅数据流。我认为更具响应性的用户界面和更好的离线支持的优势是绝对值得尝试的。如果你正在设计数据系统，我希望你能够记住订阅更改这一方式，而不仅仅是查询当前的状态。 P482

Exactly-onece 执行操作 P485

TCP使用序列号来检测网络上是否有数据包丢失或重复，并最终确保数据包以正确的顺序接受。 P486

唯一性约束需要达成共识：如果有多个具有相同值的并发请求，系统需要决定接受哪一个操作，并根据违法约束拒绝其他操作 P489

达成这一共识的最常见的方式是将单一节点作为主节点，并负责作出所有的决定。 P489

日志机制可以确保所有消费者以相同的顺序查看消息，这种保证在形式上被称为全序关系广播，他等价于共识问题 P490

多分区请求处理 P491

事实证明，使用分区日志是可以实现同等的正确性，并却不需要原子提交 P491

* 账户A向账户B转账的请求由客户端赋予一个唯一的请求ID，基于该请求ID追加到对应的日志分区

* 流处理系统读取请求日志。对于每个请求消息，它发出两条输出消息：到付款人账户A的付款指令（按照A进行分区），以及到收款人账户B（按照B进行分区）的信用指令。原始的请求ID都包含在这两条消息中。

* 后续操作接受上述指令，并通过请求ID急性重复数据消除，将最后的更改应用于账户余额。

数据流系统可以保证派生数据的完整性，无需原子提交，线性化或跨分区的同步协调 P 495

虽然严格的唯一性约束要求时效性和协调性，但是只要整体上保证完整性，几十发生暂时约束破坏，可以时候进行修复，因此许多应用实际上采用宽松式的约束并没有问题 P495

算法囚笼 P501
